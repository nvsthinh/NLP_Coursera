# 1. Week 1: Setiment Analysis with Logistic Regression

## 1.1. Supervised ML & Sentiment Analysis

### 1.1.1. Supervised ML Workflow

Vá» Suprervised ML, thÃ¬ cÃ³ má»™t Workflow chung nhÆ° sau:

- **BÆ°á»›c 1**: Tá»« Input lÃ  Ä‘áº·c trÆ°ng $X$ Ä‘Æ°a vÃ o Model theo $\theta$ - Prediction Function sáº½ cho ra Output dá»± Ä‘oÃ¡n $\hat{Y}$
- **BÆ°á»›c 2**: Tá»« Output dá»± Ä‘oÃ¡n $\hat{Y}$ vÃ  Output thá»±c táº¿ $Y$, sáº½ tÃ­nh Cost Function vÃ  tá»‘i Æ°u hÃ m Cost Ä‘Ã³ Ä‘á»ƒ cáº­p nháº­t tham sá»‘ $\theta$

**BÆ°á»›c 1 â†’ 2** sáº½ láº·p láº¡i $N$ láº§n vÃ  $N$ lÃ  sá»‘ lÆ°á»£ng Epochs

<p align="center">
  <img src="https://github.com/nvsthinh/NLP_Coursera/blob/main/Course_1/data/W111.png" width="400"/>
</p>

### 1.1.2. Sentiment Analysis Workflow

BÃ i toÃ¡n vá» Sentiment Analysis nÃ y, sáº½ nháº­n Ä‘áº§u vÃ o lÃ  Text, Ä‘i qua **Supervised ML Workflow** vÃ  tráº£ vá» Label

<p align="center">
  <img src="https://github.com/nvsthinh/NLP_Coursera/blob/main/Course_1/data/W112.png" width="400"/>
</p>

## 1.2. Vocabulary & Feature Extraction

BÆ°á»›c Ä‘áº§u tiÃªn cá»§a Workflow lÃ  lÃ m sao Ä‘á»ƒ biáº¿n Ä‘á»•i Text thÃ nh X Ä‘á»ƒ Model cÃ³ thá»ƒ há»c Ä‘Æ°á»£c.

CÃ¡ch cÆ¡ báº£n nháº¥t, khá»Ÿi táº¡o má»™t Vector vá»›i Ä‘á»™ dÃ i lÃ  báº±ng vá»›i Vocabulary $V$. Sau Ä‘Ã³, nhá»¯ng tá»« nÃ o xuáº¥t hiá»‡n trong Ä‘Ã³ sáº½ báº±ng 1, cÃ²n láº¡i sáº½ báº±ng 0

NhÆ°ng Ä‘iá»ƒm yáº¿u cá»§a phÆ°Æ¡ng phÃ¡p nÃ y, lÃ  náº¿u $V$ quÃ¡ lá»›n thÃ¬ sáº½ máº¥t nhiá»u thá»i gian Ä‘á»ƒ huáº¥n luyá»‡n cÅ©ng nhÆ° Ä‘Æ°a ra dá»± Ä‘oÃ¡n

<p align="center">
  <img src="https://github.com/nvsthinh/NLP_Coursera/blob/main/Course_1/data/W120.png" width="400"/>
</p>

## 1.3. Feature Extraction with Frequencies

CÃ³ má»™t cÃ¡ch Ä‘á»ƒ trÃ¡nh Ä‘iá»ƒm yáº¿u cá»§a phÆ°Æ¡ng phÃ¡p trÃªn lÃ  Ä‘áº¿m sá»‘ láº§n xuáº¥t hiá»‡n cá»§a tá»« Ä‘Ã³ trÃªn Positive Tweets vÃ  cáº£ Negative Tweets. ChÃºng ta cÃ³ vÃ­ dá»¥ nhÆ° sau:

Cho má»™t corpus vá»›i positive vÃ  negative tweets nhÆ° sau:

<p align="center">
  <img src="https://github.com/nvsthinh/NLP_Coursera/blob/main/Course_1/data/W130.png" width="400"/>
</p>

ChÃºng ta cáº§n pháº£i táº¡o má»™t dictionary Ä‘á»ƒ map tá»« trong cÃ¢u vÃ  class cá»§a hiá»‡n á»©ng vá»›i tá»« Ä‘Ã³ (positive hay negative) lÃ  sá»‘ lÆ°á»£ng xuáº¥t hiá»‡n cá»§a tá»« Ä‘Ã³ theo class

<p align="center">
  <img src="https://github.com/nvsthinh/NLP_Coursera/blob/main/Course_1/data/W131.png" width="400"/>
</p>

ChÃºng ta cÃ³ thá»ƒ táº¡o vector Ä‘áº·c trÆ°ng báº±ng cÃ¡ch Ä‘áº¿m sá»‘ tá»« xuáº¥t hiá»‡n nhÆ° sau Ä‘á»‘i vá»›i class positive:

<p align="center">
  <img src="https://github.com/nvsthinh/NLP_Coursera/blob/main/Course_1/data/W132.png" width="400"/>
</p>

TÆ°Æ¡ng á»©ng vá»›i class negative 

<p align="center">
  <img src="https://github.com/nvsthinh/NLP_Coursera/blob/main/Course_1/data/W133.png" width="400"/>
</p>

## 1.4. Preprocessing

TrÆ°á»›c khi biáº¿n tá»« Text sang $X$, thÃ¬ chÃºng ta cáº§n pháº£i clear Text Ä‘Ã³ vá» cÃ¹ng má»™t format. VÃ­ dá»¥ nhÆ° sau:

<p align="center">
  <img src="https://github.com/nvsthinh/NLP_Coursera/blob/main/Course_1/data/W140.png" width="400"/>
</p>

## 1.5. Putting it all together

Tiáº¿p theo thÃ¬ chÃºng ta sáº½ gom láº¡i táº¥t cáº£ cÃ¡c bÆ°á»›c Ä‘Ã£ há»c Ä‘á»ƒ á»©ng dá»¥ng bÃ i toÃ¡n nhÆ° sau

Vá» tá»•ng quan, ChÃºng ta báº¯t Ä‘áº§u vá»›i má»™t Ä‘oáº¡n Text, xá»­ lÃ½ Preprocessing, vÃ  trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng Ä‘á»ƒ chuyá»ƒn tá»« Text sang Number nhÆ° sau:

<p align="center">
  <img src="https://github.com/nvsthinh/NLP_Coursera/blob/main/Course_1/data/W150.png" width="400"/>
</p>

LÃ m tÆ°Æ¡ng tá»± vá»›i $m$ samples, thÃ¬ chÃºng ta cÃ³ $ğ‘‹$ cÃ³ chiá»u tÆ°Æ¡ng á»©ng $(ğ‘š,3)$ lÃ 

<p align="center">
  <img src="https://github.com/nvsthinh/NLP_Coursera/blob/main/Course_1/data/W151.png" width="400"/>
</p>

Vá»›i cÃ¡ch diá»…n giáº£i báº±ng code ta cÃ³ nhÆ° sau

<p align="center">
  <img src="https://github.com/nvsthinh/NLP_Coursera/blob/main/Course_1/data/W152.png" width="400"/>
</p>

## 1.6. Logistic Regression Overview

Sau khi trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng rá»“i, thÃ¬ chÃºng ta sáº½ sá»­ dá»¥ng mÃ´ hÃ¬nh Ä‘á»ƒ huáº¥n luyá»‡n vÃ  Ä‘Æ°a ra dá»± Ä‘oÃ¡n phÃ¹ há»£p Ä‘á»‘i vá»›i Output cá»§a bÃ i toÃ¡n. Vá» cÆ¡ báº£n thÃ¬ chÃºng ta sáº½ báº¯t Ä‘áº§u vá»›i Logistic Regression

Logistic regression sá»­ dá»¥ng hÃ m Sigmoid Ä‘á»ƒ cho Output lÃ  xÃ¡c suáº¥t náº±m giá»¯a 0 vÃ  1. HÃ m Sigmoid viáº¿t dÆ°á»›i dáº¡ng cÃ³ biáº¿n lÃ  tham sá»‘ $\theta$ vÃ  Inpu $ğ‘¥(ğ‘–)$ nhÆ° sau:

<p align="center">
  <img src="https://github.com/nvsthinh/NLP_Coursera/blob/main/Course_1/data/W160.png" width="400"/>
</p>

VÃ­ dá»¥ cá»¥ thá»ƒ nhÆ° sau:

<p align="center">
  <img src="https://github.com/nvsthinh/NLP_Coursera/blob/main/Course_1/data/W161.png" width="400"/>
</p>

## 1.7. **Logistic Regression: Training**

Sau khi hiá»ƒu model Logistic Regression, thÃ¬ tá»›i bÆ°á»›c huáº¥n luyá»‡n theo flow nhÆ° sau:

<p align="center">
  <img src="https://github.com/nvsthinh/NLP_Coursera/blob/main/Course_1/data/W170.png" width="400"/>
</p>

ThÃ¬ khi huáº¥n luyá»‡n xong thÃ¬ hÃ m Cost cÃ³ giÃ¡ trá»‹ theo Epoch nhÆ° sau:

<p align="center">
  <img src="https://github.com/nvsthinh/NLP_Coursera/blob/main/Course_1/data/W180.png" width="400"/>
</p>

## 1.8. L**ogistic Regression: Testing**

Sau khi huáº¥n luyá»‡n, thÃ¬ chÃºng ta sáº½ kiá»ƒm thá»­ vá»›i $X_{val}, Y_{val}, \theta$

Vá»›i Output Ä‘áº§u ra lÃ  $h(X_{val},\theta)$. ChÃºng ta sáº½ láº¥y nhá»¯ng sample cÃ³ xÃ¡c suáº¥t lá»›n hÆ¡n 0.5 lÃ  1 vÃ  nhá» hÆ¡n lÃ  0. NhÆ° sau:

<p align="center">
  <img src="https://github.com/nvsthinh/NLP_Coursera/blob/main/Course_1/data/W180.png" width="400"/>
</p>

Sau khi cÃ³ Output cÃ³ format nhÆ° class thÃ¬ chÃºng ta sáº½ tÃ­nh Accuracy giá»¯a Dá»± Ä‘oÃ¡n vÃ  Thá»±c táº¿

<p align="center">
  <img src="https://github.com/nvsthinh/NLP_Coursera/blob/main/Course_1/data/W181.png" width="400"/>
</p>

## 1.9. **Logistic Regression: Cost Function**

HÃ m Cost Function cá»§a Logistic Regression lÃ  hÃ m Binary Cross Entropy

$$
J(\theta) = -\frac{1}{m} \sum_{i=1}^{m} \left[ y^{(i)} \log h\left(x^{(i)}, \theta\right) + \left(1 - y^{(i)}\right) \log \left(1 - h\left(x^{(i)}, \theta\right)\right) \right]
$$

<p align="center">
  <img src="https://github.com/nvsthinh/NLP_Coursera/blob/main/Course_1/data/W190.png" width="400"/>
</p>